{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import applications\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_width, img_height = 150, 150\n",
    "image_size = (img_width, img_height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [01:05<00:00, 614.42it/s]\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('../data/train_v2.csv')\n",
    "\n",
    "with open('../label_maps.yml', 'r') as lablels:\n",
    "    label_data = yaml.load(lablels)\n",
    "inv_label_map = label_data['inv_label_map']\n",
    "label_map = label_data['label_map']\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for f, tags in tqdm(df_train.values, miniters=1000):\n",
    "    img = cv2.imread('../data/train-jpg/{}.jpg'.format(f))\n",
    "    targets = np.zeros(17)\n",
    "    for t in tags.split(' '):\n",
    "        targets[label_map[t]] = 1 \n",
    "    x_train.append(cv2.resize(img, image_size))\n",
    "    y_train.append(targets)\n",
    "    \n",
    "    \n",
    "y_train = np.array(y_train, np.uint8)\n",
    "x_train = np.array(x_train, np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34407, 150, 150, 3)\n",
      "(34407, 17)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.15, random_state=42)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train[:10]\n",
    "x_valid = x_valid[:5]\n",
    "y_train = y_train[:10]\n",
    "y_valid = y_valid[:5]\n",
    "nb_train_samples = len(x_train)\n",
    "nb_validation_samples = len(x_valid)\n",
    "epochs = 50\n",
    "batch_size = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_bottlebeck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the VGG16 network\n",
    "    print('Loading VGG16 model')\n",
    "    model = applications.VGG16(include_top=False, weights='imagenet')\n",
    "\n",
    "    # generator dose not shuffle images, the output should be in the same order as the data\n",
    "    print('Starting process training data')\n",
    "    generator = datagen.flow(\n",
    "        x_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size, verbose = 1)\n",
    "    print(bottleneck_features_train.dtype)\n",
    "    np.save(open('../models/bottleneck_features_train.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "    \n",
    "    print('Starting process validation data')\n",
    "    generator = datagen.flow(\n",
    "        x_valid,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size, verbose = 1)\n",
    "    np.save(open('../models/bottleneck_features_validation.npy', 'wb'),\n",
    "            bottleneck_features_validation)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading VGG16 model\n",
      "Starting process training data\n",
      "10/10 [==============================] - 1s     \n",
      "float32\n",
      "Starting process validation data\n",
      "5/5 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "save_bottlebeck_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_top_model():\n",
    "    train_data = np.load(open('../models/bottleneck_features_train.npy', 'rb'))\n",
    "    train_labels = y_train\n",
    "\n",
    "    validation_data = np.load(open('../models/bottleneck_features_validation.npy', 'rb'))\n",
    "    validation_labels = y_valid\n",
    "\n",
    "    model = Sequential()\n",
    "    print(train_data.shape[1:])\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(17, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 4, 512)\n",
      "Train on 10 samples, validate on 5 samples\n",
      "Epoch 1/50\n",
      "10/10 [==============================] - 0s - loss: 0.4748 - acc: 0.8294 - val_loss: 0.6803 - val_acc: 0.8353\n",
      "Epoch 2/50\n",
      "10/10 [==============================] - 0s - loss: 0.3495 - acc: 0.8882 - val_loss: 0.7271 - val_acc: 0.8353\n",
      "Epoch 3/50\n",
      "10/10 [==============================] - 0s - loss: 0.2648 - acc: 0.9000 - val_loss: 0.6961 - val_acc: 0.8235\n",
      "Epoch 4/50\n",
      "10/10 [==============================] - 0s - loss: 0.3162 - acc: 0.9000 - val_loss: 0.6686 - val_acc: 0.8353\n",
      "Epoch 5/50\n",
      "10/10 [==============================] - 0s - loss: 0.2866 - acc: 0.9118 - val_loss: 0.6356 - val_acc: 0.8471\n",
      "Epoch 6/50\n",
      "10/10 [==============================] - 0s - loss: 0.2093 - acc: 0.9353 - val_loss: 0.6750 - val_acc: 0.8353\n",
      "Epoch 7/50\n",
      "10/10 [==============================] - 0s - loss: 0.1999 - acc: 0.9235 - val_loss: 0.8292 - val_acc: 0.8118\n",
      "Epoch 8/50\n",
      "10/10 [==============================] - 0s - loss: 0.2321 - acc: 0.9059 - val_loss: 0.6765 - val_acc: 0.8353\n",
      "Epoch 9/50\n",
      "10/10 [==============================] - 0s - loss: 0.1698 - acc: 0.9412 - val_loss: 0.7252 - val_acc: 0.8471\n",
      "Epoch 10/50\n",
      "10/10 [==============================] - 0s - loss: 0.2182 - acc: 0.9294 - val_loss: 0.8065 - val_acc: 0.8353\n",
      "Epoch 11/50\n",
      "10/10 [==============================] - 0s - loss: 0.1711 - acc: 0.9353 - val_loss: 0.7760 - val_acc: 0.8235\n",
      "Epoch 12/50\n",
      "10/10 [==============================] - 0s - loss: 0.1855 - acc: 0.9353 - val_loss: 0.8080 - val_acc: 0.8353\n",
      "Epoch 13/50\n",
      "10/10 [==============================] - 0s - loss: 0.1689 - acc: 0.9412 - val_loss: 0.7007 - val_acc: 0.8353\n",
      "Epoch 14/50\n",
      "10/10 [==============================] - 0s - loss: 0.1521 - acc: 0.9353 - val_loss: 0.7445 - val_acc: 0.8353\n",
      "Epoch 15/50\n",
      "10/10 [==============================] - 0s - loss: 0.1976 - acc: 0.9235 - val_loss: 0.6939 - val_acc: 0.8118\n",
      "Epoch 16/50\n",
      "10/10 [==============================] - 0s - loss: 0.1715 - acc: 0.9353 - val_loss: 0.7861 - val_acc: 0.8118\n",
      "Epoch 17/50\n",
      "10/10 [==============================] - 0s - loss: 0.1220 - acc: 0.9471 - val_loss: 0.8873 - val_acc: 0.8353\n",
      "Epoch 18/50\n",
      "10/10 [==============================] - 0s - loss: 0.1346 - acc: 0.9471 - val_loss: 0.8164 - val_acc: 0.8353\n",
      "Epoch 19/50\n",
      "10/10 [==============================] - 0s - loss: 0.1879 - acc: 0.9353 - val_loss: 0.7344 - val_acc: 0.8353\n",
      "Epoch 20/50\n",
      "10/10 [==============================] - 0s - loss: 0.1365 - acc: 0.9471 - val_loss: 0.7540 - val_acc: 0.8353\n",
      "Epoch 21/50\n",
      "10/10 [==============================] - 0s - loss: 0.1336 - acc: 0.9529 - val_loss: 0.8249 - val_acc: 0.8353\n",
      "Epoch 22/50\n",
      "10/10 [==============================] - 0s - loss: 0.1351 - acc: 0.9353 - val_loss: 0.8569 - val_acc: 0.8353\n",
      "Epoch 23/50\n",
      "10/10 [==============================] - 0s - loss: 0.1336 - acc: 0.9471 - val_loss: 0.9418 - val_acc: 0.8353\n",
      "Epoch 24/50\n",
      "10/10 [==============================] - 0s - loss: 0.1479 - acc: 0.9353 - val_loss: 0.8891 - val_acc: 0.8353\n",
      "Epoch 25/50\n",
      "10/10 [==============================] - 0s - loss: 0.1216 - acc: 0.9588 - val_loss: 0.9530 - val_acc: 0.8353\n",
      "Epoch 26/50\n",
      "10/10 [==============================] - 0s - loss: 0.1190 - acc: 0.9588 - val_loss: 0.9189 - val_acc: 0.8353\n",
      "Epoch 27/50\n",
      "10/10 [==============================] - 0s - loss: 0.1175 - acc: 0.9412 - val_loss: 1.0629 - val_acc: 0.8353\n",
      "Epoch 28/50\n",
      "10/10 [==============================] - 0s - loss: 0.1310 - acc: 0.9412 - val_loss: 1.0617 - val_acc: 0.8235\n",
      "Epoch 29/50\n",
      "10/10 [==============================] - 0s - loss: 0.1214 - acc: 0.9529 - val_loss: 1.0152 - val_acc: 0.8235\n",
      "Epoch 30/50\n",
      "10/10 [==============================] - 0s - loss: 0.1454 - acc: 0.9412 - val_loss: 1.0403 - val_acc: 0.8353\n",
      "Epoch 31/50\n",
      "10/10 [==============================] - 0s - loss: 0.1039 - acc: 0.9471 - val_loss: 1.1800 - val_acc: 0.8353\n",
      "Epoch 32/50\n",
      "10/10 [==============================] - 0s - loss: 0.1116 - acc: 0.9471 - val_loss: 1.1444 - val_acc: 0.8353\n",
      "Epoch 33/50\n",
      "10/10 [==============================] - 0s - loss: 0.1099 - acc: 0.9412 - val_loss: 1.0962 - val_acc: 0.8118\n",
      "Epoch 34/50\n",
      "10/10 [==============================] - 0s - loss: 0.0820 - acc: 0.9588 - val_loss: 1.1489 - val_acc: 0.8353\n",
      "Epoch 35/50\n",
      "10/10 [==============================] - 0s - loss: 0.0964 - acc: 0.9529 - val_loss: 1.2662 - val_acc: 0.8118\n",
      "Epoch 36/50\n",
      "10/10 [==============================] - 0s - loss: 0.1190 - acc: 0.9471 - val_loss: 1.1191 - val_acc: 0.8118\n",
      "Epoch 37/50\n",
      "10/10 [==============================] - 0s - loss: 0.1107 - acc: 0.9471 - val_loss: 1.2332 - val_acc: 0.8235\n",
      "Epoch 38/50\n",
      "10/10 [==============================] - 0s - loss: 0.1312 - acc: 0.9471 - val_loss: 1.2160 - val_acc: 0.8235\n",
      "Epoch 39/50\n",
      "10/10 [==============================] - 0s - loss: 0.0821 - acc: 0.9529 - val_loss: 1.3136 - val_acc: 0.8235\n",
      "Epoch 40/50\n",
      "10/10 [==============================] - 0s - loss: 0.0786 - acc: 0.9529 - val_loss: 1.3052 - val_acc: 0.8353\n",
      "Epoch 41/50\n",
      "10/10 [==============================] - 0s - loss: 0.1087 - acc: 0.9412 - val_loss: 1.3351 - val_acc: 0.8118\n",
      "Epoch 42/50\n",
      "10/10 [==============================] - 0s - loss: 0.1289 - acc: 0.9588 - val_loss: 1.2496 - val_acc: 0.8118\n",
      "Epoch 43/50\n",
      "10/10 [==============================] - 0s - loss: 0.0880 - acc: 0.9588 - val_loss: 1.2232 - val_acc: 0.8353\n",
      "Epoch 44/50\n",
      "10/10 [==============================] - 0s - loss: 0.1062 - acc: 0.9588 - val_loss: 1.2406 - val_acc: 0.8118\n",
      "Epoch 45/50\n",
      "10/10 [==============================] - 0s - loss: 0.1034 - acc: 0.9471 - val_loss: 1.3009 - val_acc: 0.8235\n",
      "Epoch 46/50\n",
      "10/10 [==============================] - 0s - loss: 0.0945 - acc: 0.9588 - val_loss: 1.5452 - val_acc: 0.8353\n",
      "Epoch 47/50\n",
      "10/10 [==============================] - 0s - loss: 0.0996 - acc: 0.9529 - val_loss: 1.4289 - val_acc: 0.8353\n",
      "Epoch 48/50\n",
      "10/10 [==============================] - 0s - loss: 0.1139 - acc: 0.9529 - val_loss: 1.3216 - val_acc: 0.8353\n",
      "Epoch 49/50\n",
      "10/10 [==============================] - 0s - loss: 0.1107 - acc: 0.9471 - val_loss: 1.3239 - val_acc: 0.8353\n",
      "Epoch 50/50\n",
      "10/10 [==============================] - 0s - loss: 0.0886 - acc: 0.9529 - val_loss: 1.4060 - val_acc: 0.8118\n"
     ]
    }
   ],
   "source": [
    "train_top_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
