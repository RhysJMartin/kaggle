{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import SGD, RMSprop\n",
    "import logging\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {'last_activation':'sigmoid', 'output_size': 17, 'loss':'binary_crossentropy', 'input_shape':(150,150), \n",
    "           'valid_size': 0.15, 'random_state':42}\n",
    "inception_v3_phase_1 = {'name':'inception_v3', 'phase':'top_layer', 'batch_size': 16, 'optimiser':'rmsprop'}\n",
    "inception_v3_phase_2 = {'name':'inception_v3', 'phase':'full_1', 'batch_size': 32, 'optimiser':'sgd',\n",
    "                   'lr':0.01, 'momentum':0.9, 'train_from': 'inception_v3_top_layer_00_0.191.hdf5', 'epochs':100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create data generators\n",
    "def get_labels():\n",
    "    with open('../label_maps.yml', 'r') as lablels:\n",
    "        label_data = yaml.load(lablels)\n",
    "    inv_label_map = label_data['inv_label_map']\n",
    "    label_map = label_data['label_map']\n",
    "    return label_map, inv_label_map\n",
    "\n",
    "label_map, inv_label_map = get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/40479 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images and resize to (150, 150)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [01:50<00:00, 366.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 2.32 GB\n",
      "input shape: (34407, 150, 150, 3)\n",
      "Train data size: 0.41 GB\n",
      "input shape: (6072, 150, 150, 3)\n"
     ]
    }
   ],
   "source": [
    "def load_images_and_resize(label_map, input_shape, valid_size, random_state, verbose=1):\n",
    "    df_train = pd.read_csv('../data/train_v2.csv')\n",
    "    if verbose:\n",
    "        print('Loading images and resize to {}'.format(input_shape))\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for f, tags in tqdm(df_train.values, miniters=1000):\n",
    "        img = cv2.imread('../data/train-jpg/{}.jpg'.format(f))\n",
    "        targets = np.zeros(17)\n",
    "        for t in tags.split(' '):\n",
    "            targets[label_map[t]] = 1 \n",
    "        x_train.append(cv2.resize(img, input_shape))\n",
    "        y_train.append(targets)\n",
    "    y_train = np.array(y_train, np.uint8)\n",
    "    x_train = np.array(x_train, np.uint8)\n",
    "    \n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_train,\n",
    "                                                          y_train,\n",
    "                                                          test_size=valid_size,\n",
    "                                                          random_state=random_state)\n",
    "    \n",
    "    if verbose == 1:\n",
    "        print('Train data size: {:.2f} GB'.format(sys.getsizeof(x_train)/1e9))\n",
    "        print('input shape: {}'.format(x_train.shape))\n",
    "        print('Train data size: {:.2f} GB'.format(sys.getsizeof(x_valid)/1e9))\n",
    "        print('input shape: {}'.format(x_valid.shape))\n",
    "    \n",
    "    return x_train, x_valid, y_train, y_valid\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = load_images_and_resize(label_map, settings['input_shape'],\n",
    "                                                            settings['valid_size'],\n",
    "                                                            settings['random_state'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "valid_generator = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_top_layer(base_model, settings):\n",
    "    # add a global spatial average pooling layer\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    # let's add a fully-connected layer\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    # and a logistic layer -- let's say we have 200 classes\n",
    "    predictions = Dense(settings['output_size'], activation=settings['last_activation'])(x)\n",
    "\n",
    "    # this is the model we will train\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "    # first: train only the top layers (which were randomly initialized)\n",
    "    # i.e. freeze all convolutional InceptionV3 layers\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pre trained model..\n",
      "setting optimiser\n",
      "compiling model\n",
      "Load generators\n",
      "Starting training..\n",
      "Epoch 1/20\n",
      " 158/1075 [===>..........................] - ETA: 495s - loss: 0.1633 - acc: 0.9403"
     ]
    }
   ],
   "source": [
    "def train_cnn(x_train, y_train, x_valid, y_valid, settings, phase):\n",
    "    file_path = '../models/{}_{}_'.format(phase['name'], phase['phase']) + '{epoch:02d}_{val_loss:.3f}.hdf5'\n",
    "    model_checkpoint = ModelCheckpoint(file_path, monitor='val_loss',\n",
    "                                   verbose=0, save_best_only=False, \n",
    "                                save_weights_only=False, mode='auto',\n",
    "                                   period=1)\n",
    "    es = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=1, mode='auto')\n",
    "    \n",
    "    # create the base pre-trained model\n",
    "    if phase['phase'] == 'top_layer':\n",
    "        if phase['name'] == 'inception_v3':\n",
    "            print('Loading model {} with no top layer'.format(phase['name']))\n",
    "            base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "            model = add_top_layer(base_model, settings)\n",
    "    elif 'full' in phase['phase']:\n",
    "        if phase['name'] == 'inception_v3':\n",
    "            # load model\n",
    "            print('loading pre trained model..')\n",
    "            model = load_model('../models/{}'.format(phase['train_from']))\n",
    "            for layer in model.layers[:172]:\n",
    "               layer.trainable = True\n",
    "            for layer in model.layers[172:]:\n",
    "               layer.trainable = True\n",
    "    \n",
    "    print('setting optimiser')\n",
    "    if phase['optimiser'] == 'rmsprop':\n",
    "        optimiser = RMSprop()\n",
    "    if phase['optimiser'] == 'sgd':\n",
    "        optimiser = SGD(lr=phase['lr'], momentum=phase['momentum'])\n",
    "    \n",
    "    # compile the model (should be done *after* setting layers to non-trainable)\n",
    "    print('compiling model')\n",
    "    model.compile(optimizer=optimiser, loss=settings['loss'], metrics=['accuracy'])\n",
    "    \n",
    "    print('Load generators')\n",
    "    train_generator = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "    train_generator_loaded = train_generator.flow(x_train, y_train, batch_size=phase['batch_size'])\n",
    "\n",
    "    valid_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "    valid_generator_loaded = valid_generator.flow(x_valid, y_valid, batch_size=phase['batch_size'], \n",
    "                                                  shuffle=False)\n",
    "    \n",
    "    \n",
    "    print('Starting training..')\n",
    "    model.fit_generator(train_generator_loaded,\n",
    "                    steps_per_epoch= len(x_train) / phase['batch_size'],\n",
    "                    epochs=settings['epochs'], validation_data=valid_generator_loaded,\n",
    "                    validation_steps = len(x_valid) / phase['batch_size'],\n",
    "                    callbacks = [model_checkpoint, es], verbose=1)\n",
    "    \n",
    "    return model\n",
    "    \n",
    "model = train_cnn(x_train, y_train, x_valid, y_valid, settings, inception_v3_phase_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
