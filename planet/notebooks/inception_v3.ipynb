{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import backend as K\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.models import load_model\n",
    "import logging\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "settings = {'activation':'sigmoid', 'output_size': 17, 'loss':'binary_crossentropy'}\n",
    "inception_v3 = {'name':'inception_v3', 'input_shape': (299,299,3), 'batch_size': 16}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create data generators\n",
    "def get_labels():\n",
    "    with open('../label_maps.yml', 'r') as lablels:\n",
    "        label_data = yaml.load(lablels)\n",
    "    inv_label_map = label_data['inv_label_map']\n",
    "    label_map = label_data['label_map']\n",
    "    return label_map, inv_label_map\n",
    "\n",
    "label_map, inv_label_map = get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40479/40479 [01:17<00:00, 521.54it/s]\n"
     ]
    }
   ],
   "source": [
    "def load_images_and_resize(img_shape, output_size):\n",
    "    df_train = pd.read_csv('../data/train_v2.csv')\n",
    "    logging.info('Loading images and resize to {}'.format(img_shape))\n",
    "    x_train = []\n",
    "    y_train = []\n",
    "    for f, tags in tqdm(df_train.values, miniters=1000):\n",
    "        img = cv2.imread('../data/train-jpg/{}.jpg'.format(f))\n",
    "        targets = np.zeros(17)\n",
    "        for t in tags.split(' '):\n",
    "            targets[label_map[t]] = 1 \n",
    "        x_train.append(cv2.resize(img, img_shape))\n",
    "        y_train.append(targets)\n",
    "    y_train = np.array(y_train, np.uint8)\n",
    "    x_train = np.array(x_train, np.uint8)\n",
    "    \n",
    "    x_train, x_valid, y_train, y_valid = train_test_split(x_train,\n",
    "                                                          y_train,\n",
    "                                                          test_size=0.15,\n",
    "                                                          random_state=42)\n",
    "    \n",
    "    return x_train, x_valid, y_train, y_valid\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = load_images_and_resize(inception_v3['input_shape'][:2],\n",
    "                                          settings['output_size'])\n",
    "\n",
    "nb_train_examples = len(x_train)\n",
    "nb_valid_examples = len(x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data size: 9.23 GB\n",
      "input shape: (34407, 299, 299, 3)\n",
      "Train data size: 1.63 GB\n",
      "input shape: (6072, 299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print('Train data size: {:.2f} GB'.format(sys.getsizeof(x_train)/1e9))\n",
    "print('input shape: {}'.format(x_train.shape))\n",
    "print('Train data size: {:.2f} GB'.format(sys.getsizeof(x_valid)/1e9))\n",
    "print('input shape: {}'.format(x_valid.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.1,\n",
    "        zoom_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        fill_mode='nearest')\n",
    "\n",
    "train_generator_loaded = train_generator.flow(x_train, y_train,\n",
    "                                              batch_size=inception_v3['batch_size'])\n",
    "x_train = []\n",
    "\n",
    "valid_generator = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "valid_generator_loaded = valid_generator.flow(\n",
    "        x_valid, y_valid,\n",
    "        batch_size=inception_v3['batch_size'],\n",
    "        shuffle=False)\n",
    "\n",
    "x_valid = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train top layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_path = '../models/{}_'.format(inception_v3['name']) + '{epoch:02d}_{val_loss:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(file_path, monitor='val_loss',\n",
    "                                   verbose=0, save_best_only=False, \n",
    "                                save_weights_only=False, mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "269/268 [==============================] - 650s - loss: 0.2029 - acc: 0.9253 - val_loss: 0.1764 - val_acc: 0.9297\n",
      "Epoch 2/20\n",
      "269/268 [==============================] - 622s - loss: 0.1508 - acc: 0.9419 - val_loss: 0.1492 - val_acc: 0.9421\n",
      "Epoch 3/20\n",
      "269/268 [==============================] - 623s - loss: 0.1426 - acc: 0.9454 - val_loss: 0.1419 - val_acc: 0.9461\n",
      "Epoch 4/20\n",
      "269/268 [==============================] - 623s - loss: 0.1388 - acc: 0.9471 - val_loss: 0.1332 - val_acc: 0.9491\n",
      "Epoch 5/20\n",
      "269/268 [==============================] - 623s - loss: 0.1351 - acc: 0.9483 - val_loss: 0.1288 - val_acc: 0.9511\n",
      "Epoch 6/20\n",
      "269/268 [==============================] - 623s - loss: 0.1337 - acc: 0.9490 - val_loss: 0.1367 - val_acc: 0.9479\n",
      "Epoch 7/20\n",
      "269/268 [==============================] - 623s - loss: 0.1321 - acc: 0.9499 - val_loss: 0.1231 - val_acc: 0.9534\n",
      "Epoch 8/20\n",
      "269/268 [==============================] - 622s - loss: 0.1312 - acc: 0.9504 - val_loss: 0.1250 - val_acc: 0.9523\n",
      "Epoch 9/20\n",
      "269/268 [==============================] - 623s - loss: 0.1300 - acc: 0.9503 - val_loss: 0.1230 - val_acc: 0.9535\n",
      "Epoch 10/20\n",
      "269/268 [==============================] - 623s - loss: 0.1290 - acc: 0.9509 - val_loss: 0.1238 - val_acc: 0.9533\n",
      "Epoch 11/20\n",
      "269/268 [==============================] - 624s - loss: 0.1279 - acc: 0.9517 - val_loss: 0.1267 - val_acc: 0.9530\n",
      "Epoch 12/20\n",
      "269/268 [==============================] - 623s - loss: 0.1279 - acc: 0.9516 - val_loss: 0.1245 - val_acc: 0.9537\n",
      "Epoch 00011: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f13cdab6ef0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the base pre-trained model\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False)\n",
    "\n",
    "# add a global spatial average pooling layer\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "# let's add a fully-connected layer\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "# and a logistic layer -- let's say we have 200 classes\n",
    "predictions = Dense(settings['output_size'], activation=settings['activation'])(x)\n",
    "\n",
    "# this is the model we will train\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# first: train only the top layers (which were randomly initialized)\n",
    "# i.e. freeze all convolutional InceptionV3 layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# compile the model (should be done *after* setting layers to non-trainable)\n",
    "model.compile(optimizer='rmsprop', loss=settings['loss'], metrics=['accuracy'])\n",
    "\n",
    "# train the model on the new data for a few epochs\n",
    "model.fit_generator(train_generator_loaded,\n",
    "                    steps_per_epoch=nb_train_examples / inception_v3['batch_size'],\n",
    "                    epochs=20, validation_data=valid_generator_loaded,\n",
    "                    validation_steps = nb_valid_examples / inception_v3['batch_size'],\n",
    "                    callbacks = [model_checkpoint, es], verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "# we train our model again (this time fine-tuning the top 2 inception blocks\n",
    "# alongside the top Dense layers\n",
    "#model.fit_generator(...)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_3\n",
      "1 conv2d_189\n",
      "2 batch_normalization_189\n",
      "3 activation_189\n",
      "4 conv2d_190\n",
      "5 batch_normalization_190\n",
      "6 activation_190\n",
      "7 conv2d_191\n",
      "8 batch_normalization_191\n",
      "9 activation_191\n",
      "10 max_pooling2d_9\n",
      "11 conv2d_192\n",
      "12 batch_normalization_192\n",
      "13 activation_192\n",
      "14 conv2d_193\n",
      "15 batch_normalization_193\n",
      "16 activation_193\n",
      "17 max_pooling2d_10\n",
      "18 conv2d_197\n",
      "19 batch_normalization_197\n",
      "20 activation_197\n",
      "21 conv2d_195\n",
      "22 conv2d_198\n",
      "23 batch_normalization_195\n",
      "24 batch_normalization_198\n",
      "25 activation_195\n",
      "26 activation_198\n",
      "27 average_pooling2d_19\n",
      "28 conv2d_194\n",
      "29 conv2d_196\n",
      "30 conv2d_199\n",
      "31 conv2d_200\n",
      "32 batch_normalization_194\n",
      "33 batch_normalization_196\n",
      "34 batch_normalization_199\n",
      "35 batch_normalization_200\n",
      "36 activation_194\n",
      "37 activation_196\n",
      "38 activation_199\n",
      "39 activation_200\n",
      "40 mixed0\n",
      "41 conv2d_204\n",
      "42 batch_normalization_204\n",
      "43 activation_204\n",
      "44 conv2d_202\n",
      "45 conv2d_205\n",
      "46 batch_normalization_202\n",
      "47 batch_normalization_205\n",
      "48 activation_202\n",
      "49 activation_205\n",
      "50 average_pooling2d_20\n",
      "51 conv2d_201\n",
      "52 conv2d_203\n",
      "53 conv2d_206\n",
      "54 conv2d_207\n",
      "55 batch_normalization_201\n",
      "56 batch_normalization_203\n",
      "57 batch_normalization_206\n",
      "58 batch_normalization_207\n",
      "59 activation_201\n",
      "60 activation_203\n",
      "61 activation_206\n",
      "62 activation_207\n",
      "63 mixed1\n",
      "64 conv2d_211\n",
      "65 batch_normalization_211\n",
      "66 activation_211\n",
      "67 conv2d_209\n",
      "68 conv2d_212\n",
      "69 batch_normalization_209\n",
      "70 batch_normalization_212\n",
      "71 activation_209\n",
      "72 activation_212\n",
      "73 average_pooling2d_21\n",
      "74 conv2d_208\n",
      "75 conv2d_210\n",
      "76 conv2d_213\n",
      "77 conv2d_214\n",
      "78 batch_normalization_208\n",
      "79 batch_normalization_210\n",
      "80 batch_normalization_213\n",
      "81 batch_normalization_214\n",
      "82 activation_208\n",
      "83 activation_210\n",
      "84 activation_213\n",
      "85 activation_214\n",
      "86 mixed2\n",
      "87 conv2d_216\n",
      "88 batch_normalization_216\n",
      "89 activation_216\n",
      "90 conv2d_217\n",
      "91 batch_normalization_217\n",
      "92 activation_217\n",
      "93 conv2d_215\n",
      "94 conv2d_218\n",
      "95 batch_normalization_215\n",
      "96 batch_normalization_218\n",
      "97 activation_215\n",
      "98 activation_218\n",
      "99 max_pooling2d_11\n",
      "100 mixed3\n",
      "101 conv2d_223\n",
      "102 batch_normalization_223\n",
      "103 activation_223\n",
      "104 conv2d_224\n",
      "105 batch_normalization_224\n",
      "106 activation_224\n",
      "107 conv2d_220\n",
      "108 conv2d_225\n",
      "109 batch_normalization_220\n",
      "110 batch_normalization_225\n",
      "111 activation_220\n",
      "112 activation_225\n",
      "113 conv2d_221\n",
      "114 conv2d_226\n",
      "115 batch_normalization_221\n",
      "116 batch_normalization_226\n",
      "117 activation_221\n",
      "118 activation_226\n",
      "119 average_pooling2d_22\n",
      "120 conv2d_219\n",
      "121 conv2d_222\n",
      "122 conv2d_227\n",
      "123 conv2d_228\n",
      "124 batch_normalization_219\n",
      "125 batch_normalization_222\n",
      "126 batch_normalization_227\n",
      "127 batch_normalization_228\n",
      "128 activation_219\n",
      "129 activation_222\n",
      "130 activation_227\n",
      "131 activation_228\n",
      "132 mixed4\n",
      "133 conv2d_233\n",
      "134 batch_normalization_233\n",
      "135 activation_233\n",
      "136 conv2d_234\n",
      "137 batch_normalization_234\n",
      "138 activation_234\n",
      "139 conv2d_230\n",
      "140 conv2d_235\n",
      "141 batch_normalization_230\n",
      "142 batch_normalization_235\n",
      "143 activation_230\n",
      "144 activation_235\n",
      "145 conv2d_231\n",
      "146 conv2d_236\n",
      "147 batch_normalization_231\n",
      "148 batch_normalization_236\n",
      "149 activation_231\n",
      "150 activation_236\n",
      "151 average_pooling2d_23\n",
      "152 conv2d_229\n",
      "153 conv2d_232\n",
      "154 conv2d_237\n",
      "155 conv2d_238\n",
      "156 batch_normalization_229\n",
      "157 batch_normalization_232\n",
      "158 batch_normalization_237\n",
      "159 batch_normalization_238\n",
      "160 activation_229\n",
      "161 activation_232\n",
      "162 activation_237\n",
      "163 activation_238\n",
      "164 mixed5\n",
      "165 conv2d_243\n",
      "166 batch_normalization_243\n",
      "167 activation_243\n",
      "168 conv2d_244\n",
      "169 batch_normalization_244\n",
      "170 activation_244\n",
      "171 conv2d_240\n",
      "172 conv2d_245\n",
      "173 batch_normalization_240\n",
      "174 batch_normalization_245\n",
      "175 activation_240\n",
      "176 activation_245\n",
      "177 conv2d_241\n",
      "178 conv2d_246\n",
      "179 batch_normalization_241\n",
      "180 batch_normalization_246\n",
      "181 activation_241\n",
      "182 activation_246\n",
      "183 average_pooling2d_24\n",
      "184 conv2d_239\n",
      "185 conv2d_242\n",
      "186 conv2d_247\n",
      "187 conv2d_248\n",
      "188 batch_normalization_239\n",
      "189 batch_normalization_242\n",
      "190 batch_normalization_247\n",
      "191 batch_normalization_248\n",
      "192 activation_239\n",
      "193 activation_242\n",
      "194 activation_247\n",
      "195 activation_248\n",
      "196 mixed6\n",
      "197 conv2d_253\n",
      "198 batch_normalization_253\n",
      "199 activation_253\n",
      "200 conv2d_254\n",
      "201 batch_normalization_254\n",
      "202 activation_254\n",
      "203 conv2d_250\n",
      "204 conv2d_255\n",
      "205 batch_normalization_250\n",
      "206 batch_normalization_255\n",
      "207 activation_250\n",
      "208 activation_255\n",
      "209 conv2d_251\n",
      "210 conv2d_256\n",
      "211 batch_normalization_251\n",
      "212 batch_normalization_256\n",
      "213 activation_251\n",
      "214 activation_256\n",
      "215 average_pooling2d_25\n",
      "216 conv2d_249\n",
      "217 conv2d_252\n",
      "218 conv2d_257\n",
      "219 conv2d_258\n",
      "220 batch_normalization_249\n",
      "221 batch_normalization_252\n",
      "222 batch_normalization_257\n",
      "223 batch_normalization_258\n",
      "224 activation_249\n",
      "225 activation_252\n",
      "226 activation_257\n",
      "227 activation_258\n",
      "228 mixed7\n",
      "229 conv2d_261\n",
      "230 batch_normalization_261\n",
      "231 activation_261\n",
      "232 conv2d_262\n",
      "233 batch_normalization_262\n",
      "234 activation_262\n",
      "235 conv2d_259\n",
      "236 conv2d_263\n",
      "237 batch_normalization_259\n",
      "238 batch_normalization_263\n",
      "239 activation_259\n",
      "240 activation_263\n",
      "241 conv2d_260\n",
      "242 conv2d_264\n",
      "243 batch_normalization_260\n",
      "244 batch_normalization_264\n",
      "245 activation_260\n",
      "246 activation_264\n",
      "247 max_pooling2d_12\n",
      "248 mixed8\n",
      "249 conv2d_269\n",
      "250 batch_normalization_269\n",
      "251 activation_269\n",
      "252 conv2d_266\n",
      "253 conv2d_270\n",
      "254 batch_normalization_266\n",
      "255 batch_normalization_270\n",
      "256 activation_266\n",
      "257 activation_270\n",
      "258 conv2d_267\n",
      "259 conv2d_268\n",
      "260 conv2d_271\n",
      "261 conv2d_272\n",
      "262 average_pooling2d_26\n",
      "263 conv2d_265\n",
      "264 batch_normalization_267\n",
      "265 batch_normalization_268\n",
      "266 batch_normalization_271\n",
      "267 batch_normalization_272\n",
      "268 conv2d_273\n",
      "269 batch_normalization_265\n",
      "270 activation_267\n",
      "271 activation_268\n",
      "272 activation_271\n",
      "273 activation_272\n",
      "274 batch_normalization_273\n",
      "275 activation_265\n",
      "276 mixed9_0\n",
      "277 concatenate_5\n",
      "278 activation_273\n",
      "279 mixed9\n",
      "280 conv2d_278\n",
      "281 batch_normalization_278\n",
      "282 activation_278\n",
      "283 conv2d_275\n",
      "284 conv2d_279\n",
      "285 batch_normalization_275\n",
      "286 batch_normalization_279\n",
      "287 activation_275\n",
      "288 activation_279\n",
      "289 conv2d_276\n",
      "290 conv2d_277\n",
      "291 conv2d_280\n",
      "292 conv2d_281\n",
      "293 average_pooling2d_27\n",
      "294 conv2d_274\n",
      "295 batch_normalization_276\n",
      "296 batch_normalization_277\n",
      "297 batch_normalization_280\n",
      "298 batch_normalization_281\n",
      "299 conv2d_282\n",
      "300 batch_normalization_274\n",
      "301 activation_276\n",
      "302 activation_277\n",
      "303 activation_280\n",
      "304 activation_281\n",
      "305 batch_normalization_282\n",
      "306 activation_274\n",
      "307 mixed9_1\n",
      "308 concatenate_6\n",
      "309 activation_282\n",
      "310 mixed10\n"
     ]
    }
   ],
   "source": [
    "# at this point, the top layers are well trained and we can start fine-tuning\n",
    "# convolutional layers from inception V3. We will freeze the bottom N layers\n",
    "# and train the remaining top layers.\n",
    "\n",
    "# let's visualize layer names and layer indices to see how many layers\n",
    "# we should freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "   print(i, layer.name)\n",
    "\n",
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 172 layers and unfreeze the rest:\n",
    "for layer in model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[172:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.0001, momentum=0.9), loss=settings['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30\n",
      "269/268 [==============================] - 913s - loss: 0.1262 - val_loss: 0.1224\n",
      "Epoch 14/30\n",
      "269/268 [==============================] - 899s - loss: 0.1232 - val_loss: 0.1216\n",
      "Epoch 15/30\n",
      "269/268 [==============================] - 899s - loss: 0.1217 - val_loss: 0.1209\n",
      "Epoch 16/30\n",
      "269/268 [==============================] - 899s - loss: 0.1210 - val_loss: 0.1203\n",
      "Epoch 17/30\n",
      "269/268 [==============================] - 899s - loss: 0.1202 - val_loss: 0.1199\n",
      "Epoch 18/30\n",
      "269/268 [==============================] - 892s - loss: 0.1199 - val_loss: 0.1194\n",
      "Epoch 19/30\n",
      "269/268 [==============================] - 893s - loss: 0.1190 - val_loss: 0.1191\n",
      "Epoch 20/30\n",
      "269/268 [==============================] - 889s - loss: 0.1195 - val_loss: 0.1187\n",
      "Epoch 21/30\n",
      "  3/268 [..............................] - ETA: 784s - loss: 0.1168"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-c83b887fb532>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator_loaded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_valid_examples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0minception_v3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m                     callbacks = [model_checkpoint, es], verbose=1, initial_epoch = 12)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib64/python3.4/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1888\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1889\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.4/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(train_generator_loaded,\n",
    "                    steps_per_epoch=nb_train_examples / inception_v3['batch_size'],\n",
    "                    epochs=30, validation_data=valid_generator_loaded,\n",
    "                    validation_steps = nb_valid_examples / inception_v3['batch_size'],\n",
    "                    callbacks = [model_checkpoint, es], verbose=1, initial_epoch = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100\n",
      "269/268 [==============================] - 897s - loss: 0.1176 - val_loss: 0.1163\n",
      "Epoch 22/100\n",
      "269/268 [==============================] - 885s - loss: 0.1137 - val_loss: 0.1146\n",
      "Epoch 23/100\n",
      "269/268 [==============================] - 886s - loss: 0.1137 - val_loss: 0.1130\n",
      "Epoch 24/100\n",
      "269/268 [==============================] - 889s - loss: 0.1121 - val_loss: 0.1116\n",
      "Epoch 25/100\n",
      "269/268 [==============================] - 886s - loss: 0.1102 - val_loss: 0.1105\n",
      "Epoch 26/100\n",
      "269/268 [==============================] - 889s - loss: 0.1100 - val_loss: 0.1096\n",
      "Epoch 27/100\n",
      "269/268 [==============================] - 882s - loss: 0.1085 - val_loss: 0.1089\n",
      "Epoch 28/100\n",
      "269/268 [==============================] - 896s - loss: 0.1078 - val_loss: 0.1082\n",
      "Epoch 29/100\n",
      "269/268 [==============================] - 902s - loss: 0.1063 - val_loss: 0.1072\n",
      "Epoch 30/100\n",
      "269/268 [==============================] - 902s - loss: 0.1062 - val_loss: 0.1069\n",
      "Epoch 31/100\n",
      "269/268 [==============================] - 902s - loss: 0.1057 - val_loss: 0.1063\n",
      "Epoch 32/100\n",
      "269/268 [==============================] - 901s - loss: 0.1054 - val_loss: 0.1061\n",
      "Epoch 33/100\n",
      "269/268 [==============================] - 901s - loss: 0.1041 - val_loss: 0.1053\n",
      "Epoch 34/100\n",
      "269/268 [==============================] - 902s - loss: 0.1045 - val_loss: 0.1053\n",
      "Epoch 35/100\n",
      "269/268 [==============================] - 901s - loss: 0.1039 - val_loss: 0.1047\n",
      "Epoch 36/100\n",
      "269/268 [==============================] - 901s - loss: 0.1037 - val_loss: 0.1044\n",
      "Epoch 37/100\n",
      "269/268 [==============================] - 901s - loss: 0.1025 - val_loss: 0.1040\n",
      "Epoch 38/100\n",
      "269/268 [==============================] - 902s - loss: 0.1031 - val_loss: 0.1040\n",
      "Epoch 39/100\n",
      "269/268 [==============================] - 902s - loss: 0.1025 - val_loss: 0.1034\n",
      "Epoch 40/100\n",
      "269/268 [==============================] - 902s - loss: 0.1014 - val_loss: 0.1034\n",
      "Epoch 41/100\n",
      "269/268 [==============================] - 901s - loss: 0.1013 - val_loss: 0.1028\n",
      "Epoch 42/100\n",
      "269/268 [==============================] - 901s - loss: 0.1016 - val_loss: 0.1027\n",
      "Epoch 43/100\n",
      "269/268 [==============================] - 901s - loss: 0.1008 - val_loss: 0.1024\n",
      "Epoch 44/100\n",
      "269/268 [==============================] - 902s - loss: 0.1003 - val_loss: 0.1018\n",
      "Epoch 45/100\n",
      "269/268 [==============================] - 901s - loss: 0.1003 - val_loss: 0.1018\n",
      "Epoch 46/100\n",
      "269/268 [==============================] - 901s - loss: 0.1000 - val_loss: 0.1018\n",
      "Epoch 47/100\n",
      "269/268 [==============================] - 902s - loss: 0.0996 - val_loss: 0.1017\n",
      "Epoch 48/100\n",
      "269/268 [==============================] - 902s - loss: 0.0988 - val_loss: 0.1014\n",
      "Epoch 49/100\n",
      "269/268 [==============================] - 901s - loss: 0.0991 - val_loss: 0.1012\n",
      "Epoch 50/100\n",
      "269/268 [==============================] - 902s - loss: 0.0989 - val_loss: 0.1010\n",
      "Epoch 51/100\n",
      "269/268 [==============================] - 902s - loss: 0.0983 - val_loss: 0.1008\n",
      "Epoch 52/100\n",
      "269/268 [==============================] - 902s - loss: 0.0986 - val_loss: 0.1004\n",
      "Epoch 53/100\n",
      "269/268 [==============================] - 902s - loss: 0.0976 - val_loss: 0.1004\n",
      "Epoch 54/100\n",
      "269/268 [==============================] - 902s - loss: 0.0977 - val_loss: 0.1003\n",
      "Epoch 55/100\n",
      "269/268 [==============================] - 902s - loss: 0.0976 - val_loss: 0.0999\n",
      "Epoch 56/100\n",
      "269/268 [==============================] - 901s - loss: 0.0975 - val_loss: 0.0999\n",
      "Epoch 57/100\n",
      "269/268 [==============================] - 902s - loss: 0.0976 - val_loss: 0.0997\n",
      "Epoch 58/100\n",
      "269/268 [==============================] - 902s - loss: 0.0961 - val_loss: 0.0994\n",
      "Epoch 59/100\n",
      " 53/268 [====>.........................] - ETA: 644s - loss: 0.0968"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-a3e17de7c63d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalid_generator_loaded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m                     \u001b[0mvalidation_steps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnb_valid_examples\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0minception_v3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'batch_size'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                     callbacks = [model_checkpoint, es], verbose=1, initial_epoch = 20)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib64/python3.4/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[1;32m     87\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_support_signature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_q_size, workers, pickle_safe, initial_epoch)\u001b[0m\n\u001b[1;32m   1888\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[1;32m   1889\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1890\u001b[0;31m                                                class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1891\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1892\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.4/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1631\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1632\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1633\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1634\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1635\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.4/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2227\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2228\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m-> 2229\u001b[0;31m                               feed_dict=feed_dict)\n\u001b[0m\u001b[1;32m   2230\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    765\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    766\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 767\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    768\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    769\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    963\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 965\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    966\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1013\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1014\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1015\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1016\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1017\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/usr/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1020\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.4/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1002\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[1;32m   1003\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1004\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# we chose to train the top 2 inception blocks, i.e. we will freeze\n",
    "# the first 172 layers and unfreeze the rest:\n",
    "for layer in model.layers[:172]:\n",
    "   layer.trainable = False\n",
    "for layer in model.layers[172:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss=settings['loss'])\n",
    "\n",
    "model.fit_generator(train_generator_loaded,\n",
    "                    steps_per_epoch=nb_train_examples / inception_v3['batch_size'],\n",
    "                    epochs=100, validation_data=valid_generator_loaded,\n",
    "                    validation_steps = nb_valid_examples / inception_v3['batch_size'],\n",
    "                    callbacks = [model_checkpoint, es], verbose=1, initial_epoch = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train full model\n",
    "- half model final line\n",
    "\n",
    "Epoch 58/100\n",
    "269/268 [==============================] - 902s - loss: 0.0961 - val_loss: 0.0994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/100\n",
      "216/215 [==============================] - 562s - loss: 0.0883 - val_loss: 0.0885\n",
      "Epoch 36/100\n",
      "216/215 [==============================] - 530s - loss: 0.0879 - val_loss: 0.0885\n",
      "Epoch 37/100\n",
      "216/215 [==============================] - 536s - loss: 0.0879 - val_loss: 0.0886\n",
      "Epoch 38/100\n",
      "216/215 [==============================] - 532s - loss: 0.0874 - val_loss: 0.0887\n",
      "Epoch 00037: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb0855dfbe0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# full model\n",
    "\n",
    "\n",
    "#model = load_model('../models/inception_v3_full_28_0.09.hdf5')\n",
    "\n",
    "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=1, mode='auto')\n",
    "\n",
    "file_path = '../models/{}_full_'.format(inception_v3['name']) + '{epoch:02d}_{val_loss:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(file_path, monitor='val_loss',\n",
    "                                   verbose=0, save_best_only=False, \n",
    "                                save_weights_only=False, mode='auto',\n",
    "                                   period=1)\n",
    "\n",
    "for layer in model.layers[:172]:\n",
    "   layer.trainable = True\n",
    "for layer in model.layers[172:]:\n",
    "   layer.trainable = True\n",
    "\n",
    "# we need to recompile the model for these modifications to take effect\n",
    "# we use SGD with a low learning rate\n",
    "from keras.optimizers import SGD\n",
    "model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss=settings['loss'])\n",
    "\n",
    "batch_size = inception_v3['batch_size']\n",
    "model.fit_generator(train_generator_loaded,\n",
    "                    steps_per_epoch= 0.1 * nb_train_examples / batch_size,\n",
    "                    epochs=100, validation_data=valid_generator_loaded,\n",
    "                    validation_steps = nb_valid_examples / batch_size,\n",
    "                    callbacks = [model_checkpoint, es], verbose=1, initial_epoch = 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define config for training\n",
    "\n",
    "inception_v3 = {'name':'inception_v3', 'last_activation':'sigmoid',\n",
    "                'output_size': 17, 'loss':'binary_crossentropy', 'input_shape': (299,299,3)}\n",
    "\n",
    "# possible optimisers\n",
    "rmsprop = model.compile(optimizer='rmsprop', loss=inception_v3['loss'], metrics=['accuracy'])\n",
    "sgd_1 = model.compile(optimizer=SGD(lr=0.01, momentum=0.9), loss=inception_v3['loss'], metrics=['accuracy'])\n",
    "sgd_2 = model.compile(optimizer=SGD(lr=0.003, momentum=0.9), loss=inception_v3['loss'], metrics=['accuracy'])\n",
    "sgd_3 = model.compile(optimizer=SGD(lr=0.001, momentum=0.9), loss=inception_v3['loss'], metrics=['accuracy'])\n",
    "sgd_3 = model.compile(optimizer=SGD(lr=0.0003, momentum=0.9), loss=inception_v3['loss'], metrics=['accuracy'])\n",
    "\n",
    "inception_v3_p1 = {'phase':'top_layer', 'batch_size': 128, 'optimiser': rmsprop}\n",
    "inception_v2_p2 = {'phase': 'full_1', 'batch_size': 16, 'optimiser': sgd_1,\n",
    "                   'from_saved_model':'inception_v3_full_20_0.10.hdf5', initial_epoch: 20}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# F2 score on validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('../models/inception_v3_full_37_0.09.hdf5')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "375/375 [==============================] - 111s   \n"
     ]
    }
   ],
   "source": [
    "p_valid = model.predict_generator(valid_generator_loaded, 6000/16, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92250005651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python3.4/dist-packages/sklearn/metrics/classification.py:1113: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in samples with no predicted labels.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.92250005651\n",
      "0.92706463798\n",
      "[0.2, 0.24, 0.18, 0.1, 0.16, 0.11, 0.27, 0.05, 0.1, 0.22, 0.26, 0.1, 0.32, 0.28, 0.22, 0.33, 0.26]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import fbeta_score\n",
    "simple_score = fbeta_score(y_valid[:6000], np.array(p_valid) > 0.2, beta=2, average='samples')\n",
    "print(simple_score)\n",
    "\n",
    "def get_optimal_threshhold(true_label, prediction, iterations = 100):\n",
    "\n",
    "    best_threshhold = [0.2]*17    \n",
    "    for t in range(17):\n",
    "        best_fbeta = 0\n",
    "        temp_threshhold = [0.2]*17\n",
    "        for i in range(iterations):\n",
    "            temp_value = i / float(iterations)\n",
    "            temp_threshhold[t] = temp_value\n",
    "            temp_fbeta = fbeta_score(true_label, prediction > temp_threshhold, beta=2, average='samples')\n",
    "            if  temp_fbeta > best_fbeta:\n",
    "                best_fbeta = temp_fbeta\n",
    "                best_threshhold[t] = temp_value\n",
    "    return best_threshhold\n",
    "                \n",
    "best_thrshold = get_optimal_threshhold(y_valid[:6000], p_valid, iterations = 100)\n",
    "\n",
    "opti_score = fbeta_score(y_valid[:6000], np.array(p_valid) > best_thrshold, beta=2, average='samples')\n",
    "\n",
    "print(simple_score)\n",
    "print(opti_score)\n",
    "print(best_thrshold)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# not needed now!!\n",
    "#Build InceptionV3 over a custom input tensor\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.layers import Input\n",
    "\n",
    "# this could also be the output a different Keras model or layer\n",
    "input_tensor = Input(shape=(224, 224, 3))  # this assumes K.image_data_format() == 'channels_last'\n",
    "\n",
    "model = InceptionV3(input_tensor=input_tensor, weights='imagenet', include_top=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
